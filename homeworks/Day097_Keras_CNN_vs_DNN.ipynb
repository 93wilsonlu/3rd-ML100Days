{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day097_Keras_CNN_vs_DNN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0V1fk142oegY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":81},"outputId":"13ccc65b-8cf2-418c-bd74-32faaa46ded2","executionInfo":{"status":"ok","timestamp":1577069299142,"user_tz":-480,"elapsed":2462,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7v62a2gtoegu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"fd7dd6c8-17d2-456e-ae7f-6e402015814a","executionInfo":{"status":"ok","timestamp":1577069310368,"user_tz":-480,"elapsed":13574,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["batch_size = 256 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 20 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BSLMlyp2oeg0","colab_type":"text"},"source":["## 首先我們使用一般的 DNN (MLP) 來訓練\n","由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"id":"0MwxANP3oeg1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"ca2e650c-212c-45db-fdf6-23bc700027b7","executionInfo":{"status":"ok","timestamp":1577069310911,"user_tz":-480,"elapsed":14060,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["# 將資料攤平成一維資料\n","x_train = x_train.reshape(50000, 3072) \n","x_test = x_test.reshape(10000, 3072)\n","\n","# 將資料變為 float32 並標準化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzpyvr5boeg6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f3bdddf7-3c26-4951-e390-b61705bf403d","executionInfo":{"status":"ok","timestamp":1577069345846,"user_tz":-480,"elapsed":48908,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(3072,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 512)               1573376   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","50000/50000 [==============================] - 11s 210us/step - loss: 1.9904 - acc: 0.2815 - val_loss: 1.7604 - val_acc: 0.3707\n","Epoch 2/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.7926 - acc: 0.3533 - val_loss: 1.6853 - val_acc: 0.3980\n","Epoch 3/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.7386 - acc: 0.3729 - val_loss: 1.6365 - val_acc: 0.4137\n","Epoch 4/20\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.6980 - acc: 0.3907 - val_loss: 1.6157 - val_acc: 0.4271\n","Epoch 5/20\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.6581 - acc: 0.4039 - val_loss: 1.5787 - val_acc: 0.4363\n","Epoch 6/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.6333 - acc: 0.4130 - val_loss: 1.5591 - val_acc: 0.4441\n","Epoch 7/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.6080 - acc: 0.4221 - val_loss: 1.5194 - val_acc: 0.4607\n","Epoch 8/20\n","50000/50000 [==============================] - 1s 26us/step - loss: 1.5965 - acc: 0.4250 - val_loss: 1.5318 - val_acc: 0.4532\n","Epoch 9/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5739 - acc: 0.4325 - val_loss: 1.5036 - val_acc: 0.4680\n","Epoch 10/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5540 - acc: 0.4411 - val_loss: 1.5253 - val_acc: 0.4577\n","Epoch 11/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5492 - acc: 0.4440 - val_loss: 1.4858 - val_acc: 0.4734\n","Epoch 12/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5434 - acc: 0.4449 - val_loss: 1.4844 - val_acc: 0.4721\n","Epoch 13/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5379 - acc: 0.4469 - val_loss: 1.4819 - val_acc: 0.4739\n","Epoch 14/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5274 - acc: 0.4507 - val_loss: 1.4888 - val_acc: 0.4753\n","Epoch 15/20\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.5101 - acc: 0.4594 - val_loss: 1.4642 - val_acc: 0.4788\n","Epoch 16/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.5066 - acc: 0.4569 - val_loss: 1.4710 - val_acc: 0.4732\n","Epoch 17/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.4892 - acc: 0.4651 - val_loss: 1.4611 - val_acc: 0.4806\n","Epoch 18/20\n","50000/50000 [==============================] - 1s 25us/step - loss: 1.4910 - acc: 0.4629 - val_loss: 1.4440 - val_acc: 0.4845\n","Epoch 19/20\n","50000/50000 [==============================] - 1s 26us/step - loss: 1.4802 - acc: 0.4676 - val_loss: 1.4381 - val_acc: 0.4846\n","Epoch 20/20\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.4684 - acc: 0.4706 - val_loss: 1.4560 - val_acc: 0.4768\n","Test loss: 1.4560065937042237\n","Test accuracy: 0.4768\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LjEgoLI4oeg-","colab_type":"text"},"source":["## 接下來我們使用 CNN 來訓練神經網路\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"id":"AmSOjvp1oehA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"70ea1074-2a0c-463c-f145-275bb8fd7ccf","executionInfo":{"status":"ok","timestamp":1577069346085,"user_tz":-480,"elapsed":49077,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tbhekS-yoehE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d518babc-f923-424d-ca5f-f2970887e68c","executionInfo":{"status":"ok","timestamp":1577069420912,"user_tz":-480,"elapsed":123866,"user":{"displayName":"W L","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCEPbw0E2aWq3DnKA7hWiN0gLlgFsf5hIdqcNGqfw=s64","userId":"03725006096736106015"}}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n","50000/50000 [==============================] - 9s 170us/step - loss: 1.7452 - acc: 0.3615 - val_loss: 1.3862 - val_acc: 0.5055\n","Epoch 2/20\n","50000/50000 [==============================] - 3s 67us/step - loss: 1.3335 - acc: 0.5212 - val_loss: 1.1247 - val_acc: 0.5995\n","Epoch 3/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 1.1376 - acc: 0.5957 - val_loss: 1.0339 - val_acc: 0.6352\n","Epoch 4/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.9972 - acc: 0.6481 - val_loss: 0.8606 - val_acc: 0.6978\n","Epoch 5/20\n","50000/50000 [==============================] - 3s 67us/step - loss: 0.8917 - acc: 0.6849 - val_loss: 0.8028 - val_acc: 0.7182\n","Epoch 6/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.8254 - acc: 0.7126 - val_loss: 0.7714 - val_acc: 0.7345\n","Epoch 7/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.7766 - acc: 0.7295 - val_loss: 0.7257 - val_acc: 0.7468\n","Epoch 8/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.7322 - acc: 0.7435 - val_loss: 0.6926 - val_acc: 0.7608\n","Epoch 9/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.6895 - acc: 0.7584 - val_loss: 0.6811 - val_acc: 0.7609\n","Epoch 10/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.6579 - acc: 0.7680 - val_loss: 0.6728 - val_acc: 0.7694\n","Epoch 11/20\n","50000/50000 [==============================] - 3s 67us/step - loss: 0.6254 - acc: 0.7789 - val_loss: 0.6538 - val_acc: 0.7713\n","Epoch 12/20\n","50000/50000 [==============================] - 3s 67us/step - loss: 0.5934 - acc: 0.7910 - val_loss: 0.6311 - val_acc: 0.7800\n","Epoch 13/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.5767 - acc: 0.7969 - val_loss: 0.6277 - val_acc: 0.7800\n","Epoch 14/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.5435 - acc: 0.8090 - val_loss: 0.6238 - val_acc: 0.7866\n","Epoch 15/20\n","50000/50000 [==============================] - 3s 70us/step - loss: 0.5280 - acc: 0.8123 - val_loss: 0.6276 - val_acc: 0.7828\n","Epoch 16/20\n","50000/50000 [==============================] - 3s 69us/step - loss: 0.5096 - acc: 0.8186 - val_loss: 0.6546 - val_acc: 0.7808\n","Epoch 17/20\n","50000/50000 [==============================] - 3s 70us/step - loss: 0.4918 - acc: 0.8248 - val_loss: 0.6213 - val_acc: 0.7896\n","Epoch 18/20\n","50000/50000 [==============================] - 3s 69us/step - loss: 0.4717 - acc: 0.8315 - val_loss: 0.6135 - val_acc: 0.7957\n","Epoch 19/20\n","50000/50000 [==============================] - 3s 68us/step - loss: 0.4499 - acc: 0.8400 - val_loss: 0.6055 - val_acc: 0.7946\n","Epoch 20/20\n","50000/50000 [==============================] - 3s 67us/step - loss: 0.4308 - acc: 0.8461 - val_loss: 0.6129 - val_acc: 0.7975\n","Test loss: 0.6129060239315033\n","Test accuracy: 0.7975\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7PF-RLqUoehI","colab_type":"text"},"source":["## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"aQ9cGYBgoehL","colab_type":"text"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?"]},{"cell_type":"markdown","metadata":{"id":"PKe0rkRAqTdu","colab_type":"text"},"source":["1. epoch\n","2. DNN, CNN 在卷積及池化的時候會逐步縮小影像大小，每一層的輸出參數會跟著變少"]}]}